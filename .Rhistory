library(quanteda)
library(readtext)
library(readtext) # for reading in all kinds of files
txts <- readtext("data/abortion-debate-by-speaker/*.txt")
install.packages("topicmodels")
?topicmodels
?topicmodels::build_graph
data("corpus_bara_speaker")
View(corpus_bara_speaker)
corpus_bara_speaker
summary(corpus_bara_speaker)
library(devtools)
use_vignette("lab1")
baradic <- dictionary(file="data/2007_abortion_dictionary.ykd")
baradic <- dictionary(file="session1/lab1/data/2007_abortion_dictionary.ykd")
baradic
names(baradic)
names(baradic$incoming.txt)
tab <- data.frame(mean = c(13.59, 7.82, 21.71, 4.61, 32.17, 20.09),
sd = c(2.98, 3.36, 4.73, 2.51, 6.94, 4.86),
row.names = c("advocacy", "legal", "medical", "moral", "procedural", "social" ),
stringsAsFactors = FALSE)
knitr::kable(t(tab))
?corpus_segment
?textstat_collocations
# Chunk 1: setup
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(quanteda) # for general text analysis
library(readtext) # for reading in all kinds of files
txts <- readtext("data/abortion-debate-by-speaker/*.txt")
corp <- corpus(txts)
setwd("~/wip/iqmr/vignettes")
txts <- readtext("data/abortion-debate-by-speaker/*.txt")
corp <- corpus(txts)
corp
vote <- c("abs", "abs", "abs", "no", "no", "no", "no",
"no", "yes", "yes", "yes", "yes", "yes", "yes",
"yes", "yes", "yes", "yes", "yes", "yes", "yes",
"yes", "yes", "yes")
docvars(corp, "vote") <- vote
summary(corp)
docvars(corp, "words_spoken") <- summary(corp)$Tokens
dvars <- docvars(corp)
texts(corp) # caution, quite slow to show...
texts(corp)[5]
nocorp <- corpus_subset(corp, vote == "no")
summary(nocorp)
?corpus_trim
longcorp <- corpus_trim(corp, what = "documents", min_ntoken = 50)
longcorp
corp
summary(corp)
readability <- textstat_readability(corp, "Flesch.Kincaid")
range(readability) # who is so unreadable?
which(readability > 20) # looking at you Mr Mendelson
texts(corp)[19] # yes, I mean no, I mean, what?
readability <- textstat_readability(corp, "Flesch.Kincaid")
readability
texts(corp)[19] # yes, I mean no, I mean, what?
arrange(readability, Flesch.Kincaid)
library(dplyr)
arrange(readability, Flesch.Kincaid)
toks <- tokens(corp)
head(textstat_collocations(toks, method="pmi"), 20)
toks <- tokens(corp)
textstat_collocations(toks, method="pmi")
?textstat_collocations
textstat_collocations(toks)
textstat_collocations(corp)
toks2 <- tokens_select(toks2, stopwords(),
"remove", padding = TRUE)
?tokens_remove
toks2 <- tokens_remove(toks2, stopwords(), padding = TRUE)
toks2 <- tokens_remove(tokens(corpus), stopwords(), padding = TRUE)
toks2 <- tokens_remove(tokens(corp), stopwords(), padding = TRUE)
View(toks2)
seqs <- textstat_collocations(toks2)
seqs
textstat_collocations(toks2, size = 3)
toks2 <- tokens_select(toks2, "[a-z]+", valuetype="regex",
case_insensitive = FALSE,
padding = TRUE) #
seqs <- textstat_collocations(toks2, method = "bj_uni")
seqs <- textstat_collocations(toks2)
seqs
seqs <- textstat_collocations(toks2, 3)
seqs <- textstat_collocations(toks2, size = 3)
seqs
kwic(corp, "mother*")
babes <- kwic(corp, "babi*", window=10)
txt <- paste(babes$pre, babes$post, collapse=" ") # make one big string
txt
?fcm
nfeat(corp)
nfeat(dfm(corp))
ff  <- fcm(corp, context = "window", window = 7)
ff
ff  <- fcm(corp, context = "window", window = 7, tri = FALSE)
ff
featnames(ff)
grep("bab", featnames(ff), value = TRUE)
ff  <- fcm_tolower(fcm(corp, context = "window", window = 7, tri = FALSE))
ff  <- fcm(corp, context = "window", window = 7, tri = FALSE)
colSums(ff)
table(colSums(ff) > 20)
table(colSums(ff) > 25)
table(colSums(ff) > 20)
which(colSums(ff) > 20)
table(colSums(ff) > 100)
featnames(ff)[(colSums(ff) > 100)]
featnames(ff)[(colSums(ff) > 100 & !(featnames(ff) %in% stops())]
featnames(ff)[(colSums(ff) > 100 & !(featnames(ff) %in% stops()))]
featnames(ff)[(colSums(ff) > 100 & !(featnames(ff) %in% stopwords()))]
good <- featnames(ff)[(colSums(ff) > 100 & !(featnames(ff) %in% stopwords()))]
ff[good, good]
ffsmall <- ff[good, good]
install.packages("lsa")
lsa::cosine
?lsa::cosine
lsa::cosine(ffsmall)
lsa::cosine(as.matrix(ffsmall))
#lsa::cosine(as.matrix(ffsmall))
hclust
?hclust
?hclust
?dist
plot(hclust(2*(1- lsa::cosine(ffsmall))))
plot(hclust(2*(1- lsa::cosine(as.matrix(ffsmall)))))
lcc <- lsa::cosine(as.matrix(ffsmall))
class(lcc)
dim(lcc)
dim(2*(1-lcc))
(2*(1-lcc))
diag(fcc)
diag(lcc)
diag(2*(2-fcc))
diag(2*(2-lcc))
diag(2*(1-fcc))
diag(2*(1-lcc))
hclust(lcc)
?dist
hclust(as.dist(lcc))
plot(hclust(as.dist(lcc)))
corpdfm <- dfm(corp) # lowercases by default, but nothing more
dim(corpdfm)
featnames(corpdfm)[1:40] # really just colnames
corpdfm <- dfm(corp, remove=stopwords(), remove_punct=TRUE,
remove_numbers=TRUE)
dim(corpdfm) # a little smaller
featnames(corpdfm)[1:40]
stemdfm <- dfm(corp, remove=stopwords(), remove_punct=TRUE,
remove_numbers=TRUE, stem=TRUE)
dim(stemdfm) # about 1000 fewer 'word's
featnames(stemdfm)[1:40]
smallcorpdfm <- dfm_trim(corpdfm, min_count=5, min_docfreq=5)
dim(smallcorpdfm2)
smallcorpdfm <- dfm_trim(corpdfm, min_termfreq = 5, min_docfreq=5)
dim(smallcorpdfm2)
smallcorpdfm <- dfm_trim(corpdfm, min_termfreq = 5, min_docfreq=5)
dim(smallcorpdfm2)
aggregate(words_spoken ~ vote, data=docvars(corp), FUN=sum)
aggregate(words_spoken ~ vote, data=docvars(corp), FUN=median)
aggregate(words_spoken ~ vote, data=docvars(corp), FUN=median)
dictionary(list(medics=c("doctor", "medical", "hospital"),
mothers=c("mother", "parents")))
baradic <- dictionary(file="data/2007_abortion_dictionary.ykd")
baradfm <- dfm(corp, dictionary=bara)
baradfm <- dfm(corp, dictionary = baradic)
dim(baradfm)
dictout <- as.matrix(baradfm)
dictout
tab <- data.frame(Mean = c(13.59, 7.82, 21.71, 4.61, 32.17, 20.09),
SD = c(2.98, 3.36, 4.73, 2.51, 6.94, 4.86),
row.names = c("advocacy", "legal", "medical", "moral", "procedural", "social" ),
stringsAsFactors = FALSE)
knitr::kable(t(tab))
emph <- colSums(dictout) ## emphasis
propemph <- emph / sum(emph)*100 ## relative emphasis as a percentage
barplot(propemph)
propemph
relevanttalk <- rowSums(dictout)
aggregate(relevanttalk ~ docvars(corp, "vote"), FUN=sum)
?RShowDoc
install.packages("bib2df")
read_table(pipe("pbpaste"), sep = "\t")
read.table(pipe("pbpaste"), sep = "\t")
folk <- read.table(pipe("pbpaste"), sep = "\t")
View(folk)
folk <- readxl::read_excel("~/Desktop/iqmr2018.xlsx")
View(folk)
library(tidyverse)
library(gutenbergr)
sherlock_raw <- gutenberg_download(1661)
sherlock <- sherlock_raw %>%
mutate(story = ifelse(str_detect(text, "ADVENTURE"),
text,
NA)) %>%
fill(story) %>%
filter(story != "THE ADVENTURES OF SHERLOCK HOLMES") %>%
mutate(story = factor(story, levels = unique(story)))
sherlock
install.packages("gutenbergr")
library(tidyverse)
library(gutenbergr)
sherlock_raw <- gutenberg_download(1661)
sherlock <- sherlock_raw %>%
mutate(story = ifelse(str_detect(text, "ADVENTURE"),
text,
NA)) %>%
fill(story) %>%
filter(story != "THE ADVENTURES OF SHERLOCK HOLMES") %>%
mutate(story = factor(story, levels = unique(story)))
sherlock
library(tidytext)
tidy_sherlock <- sherlock %>%
mutate(line = row_number()) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
filter(word != "holmes")
tidy_sherlock
tidy_sherlock %>%
count(word, sort = TRUE)
sherlock_tf_idf <- tidy_sherlock %>%
count(story, word, sort = TRUE) %>%
bind_tf_idf(word, story, n) %>%
arrange(-tf_idf) %>%
group_by(story) %>%
top_n(10) %>%
ungroup
sherlock_tf_idf
library(quanteda)
library(stm)
sherlock_dfm <- tidy_sherlock %>%
count(story, word, sort = TRUE) %>%
cast_dfm(story, word, n)
library(stm)
install.packages("stm")
library(stm)
library(quanteda)
library(stm)
sherlock_dfm <- tidy_sherlock %>%
count(story, word, sort = TRUE) %>%
cast_dfm(story, word, n)
install.packages("tidytext")
install.packages("tidytext")
library(tidytext)
library(quanteda)
library(stm)
sherlock_dfm <- tidy_sherlock %>%
count(story, word, sort = TRUE) %>%
cast_dfm(story, word, n)
library(tidyverse(
))
library(quanteda)
library(stm)
sherlock_dfm <- tidy_sherlock %>%
count(story, word, sort = TRUE) %>%
cast_dfm(story, word, n)
?count
tidy_sherlock
tidy_sherlock %>%
+     count(story, word, sort = TRUE)
names(tidy_sherlock)
install.packages("tidyverse")
install.packages("tidyverse")
library(tidyverse(
))
library(tidyverse)
library(gutenbergr)
sherlock_raw <- gutenberg_download(1661)
sherlock <- sherlock_raw %>%
mutate(story = ifelse(str_detect(text, "ADVENTURE"),
text,
NA)) %>%
fill(story) %>%
filter(story != "THE ADVENTURES OF SHERLOCK HOLMES") %>%
mutate(story = factor(story, levels = unique(story)))
tidy_sherlock <- sherlock %>%
mutate(line = row_number()) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
filter(word != "holmes")
tidy_sherlock %>%
count(word, sort = TRUE)
install.packages("tidytext")
library(drlin)
library(drlib)
install.packages("drlib")
library(tidyverse)
library(gutenbergr)
library(drlib)
library(tidytext)
library(quanteda)
library(stm)
sherlock_raw <- gutenberg_download(1661)
sherlock <- sherlock_raw %>%
mutate(story = ifelse(str_detect(text, "ADVENTURE"),
text,
NA)) %>%
fill(story) %>%
filter(story != "THE ADVENTURES OF SHERLOCK HOLMES") %>%
mutate(story = factor(story, levels = unique(story)))
sherlock
tidy_sherlock <- sherlock %>%
mutate(line = row_number()) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
filter(word != "holmes")
tidy_sherlock %>%
count(word, sort = TRUE)
sherlock_tf_idf <- tidy_sherlock %>%
count(story, word, sort = TRUE) %>%
bind_tf_idf(word, story, n) %>%
arrange(-tf_idf) %>%
group_by(story) %>%
top_n(10) %>%
ungroup
sherlock_dfm <- tidy_sherlock %>%
count(story, word, sort = TRUE) %>%
cast_dfm(story, word, n)
sherlock_dfm
class(sherlock_dfm)
count
sherlock_dfm2 <- tidy_sherlock %>%
cast_dfm(story, word, n)
cast_dfm
sherlock_raw
head(sherlock_raw, 30)
head(sherlock_raw, 40)
head(as.data.frame(sherlock_raw), 40)
sherlock_sparse <- tidy_sherlock %>%
count(story, word, sort = TRUE) %>%
cast_sparse(story, word, n)
sherlock_sparse
uk <- topicdict::corpus_uk_platforms
uk
#topic_model <- stm(dfm(uk, stem = TRUE, remove = stopwords(), tokens( , K = 6,
verbose = FALSE, init.type = "Spectral")
?tokens
topic_model <- stm(dfm(uk, stem = TRUE, remove = stopwords(), remove_numbers = TRUE, remove_symbols = TRUE, remove_separators = TRUE) , K = 20,
verbose = FALSE, init.type = "Spectral")
ukk <- dfm(uk, stem = TRUE, remove = stopwords(), remove_numbers = TRUE, remove_symbols = TRUE, remove_separators = TRUE)
ukk
ukk <- dfm_trim(ukk, min_termfreq = 10, min_docfreq = 10)
ukkk
ukk
mod <- topic_model <- stm(ukk, K = 20, init.type = "Spectral")
featnames(ukk)
ukk <- dfm(uk, stem = TRUE,
remove = stopwords(), remove_punctuation = TRUE,
remove_numbers = TRUE, remove_symbols = TRUE,
remove_separators = TRUE)
featnames(ukk)
ukk <- dfm(uk, remove = stopwords(),
remove_numbers = TRUE, remove_symbols = TRUE,
remove_separators = TRUE, stem = TRUE)
featnames(ukk)
?dfm
ukk <- dfm(uk, remove = stopwords(),
remove_numbers = TRUE, remove_symbols = TRUE,
remove_separators = TRUE)
featnames(ukk)
ukk <- dfm(uk, remove = stopwords(), remove_punct = TRUE,
remove_numbers = TRUE, remove_symbols = TRUE,
remove_separators = TRUE, stem = TRUE)
featnames(ukk)
ukk <- dfm_trim(ukk, min_termfreq = 10, min_docfreq = 10)
featnames(ukk)
mod <- topic_model <- stm(ukk, K = 20, init.type = "Spectral")
stm::labelTopics(mod)
docvars(ukk)
stm::thetaPosterior(mod)
colMeans(stm::thetaPosterior(mod))
class(stm::thetaPosterior(mod))
names(stm::thetaPosterior(mod))
length(stm::thetaPosterior(mod))
ukk
Reduce(`+`, stm::thetaPosterior(mod))
length(stm::thetaPosterior(mod))
?stm::thetaPosterior(mod)
lapply(stm::thetaPosterior(mod), colMeans)
lapply(lapply(stm::thetaPosterior(mod), colMeans), sum)
lapply(stm::thetaPosterior(mod), colMeans)
as.data.frame(lapply(stm::thetaPosterior(mod), colMeans))
bind_rows(lapply(stm::thetaPosterior(mod), colMeans))
bind_rows(setNames(lapply(stm::thetaPosterior(mod), colMeans), 1:109))
as.matrix(bind_rows(setNames(lapply(stm::thetaPosterior(mod), colMeans), 1:109)))
draw <- as.matrix(bind_rows(setNames(lapply(stm::thetaPosterior(mod), colMeans), 1:109)))
dist(draw)
plot(hclust(dist(draw)))
draw <- t(as.matrix(bind_rows(setNames(lapply(stm::thetaPosterior(mod), colMeans), 1:109))))
plot(hclust(dist(draw)))
draw
#rownames(draw, docvars(ukk)
docvars(ukk)
paste(docvars(ukk)[,c('date', 'party')])
paste(docvars(ukk)[,c('date', 'party')], collapse = "\n")
paste(docvars(ukk)[,c('date', 'party')], sep = "\n")
docvars(ukk)[,c('date', 'party')]
paste(docvars(ukk)[,c('date', 'party')])
cbind(docvars(ukk)[,c('date', 'party')])
rownames(draw) <- paste(docvars(ukk)$date, docvars(ukk)$party)
draw
plot(hclust(dist(draw)))
draw
colSums(draw)
stm::labelTopics(mod)
draw[,10]
plot(docvars(ukk, "year"), draw[,10])
plot(docvars(ukk, "date"), draw[,10])
scatter.smooth(docvars(ukk, "date"), draw[,10])
scatter.smooth(docvars(ukk, "date"), draw[,11])
scatter.smooth(docvars(ukk, "date"), draw[,12])
scatter.smooth(docvars(ukk, "date"), draw[,13])
scatter.smooth(docvars(ukk, "date"), draw[,14])
scatter.smooth(docvars(ukk, "date"), draw[,15])
scatter.smooth(docvars(ukk, "date"), draw[,16])
scatter.smooth(docvars(ukk, "date"), draw[,18])
scatter.smooth(docvars(ukk, "date"), draw[,19])
